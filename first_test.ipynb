{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import pipeline\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from huggingface_hub import InferenceClient\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "#os.environ[\"HF_TOKEN\"]=\n",
    "HF_TOKEN=\"something\"\n",
    "client = InferenceClient(api_key=HF_TOKEN)#\n",
    "#srun -N1 --gpus-per-node=1 -t 500 --pty bash\n",
    "# jupyter notebook\n",
    "#example \n",
    "output = client.text_generation(\n",
    "    \"The capital of France is\",\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Table name :Iris\\n(column_index, column_name, data_type, not_null, default_value, primary_key)\\n[(0, 'Id', 'INTEGER', 0, None, 1), (1, 'SepalLengthCm', 'NUMERIC', 0, None, 0), (2, 'SepalWidthCm', 'NUMERIC', 0, None, 0), (3, 'PetalLengthCm', 'NUMERIC', 0, None, 0), (4, 'PetalWidthCm', 'NUMERIC', 0, None, 0), (5, 'Species', 'TEXT', 0, None, 0)]\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_table_info(database_name:str='database.sqlite')-> str:\n",
    "        \"\"\"\n",
    "        return description of dataset\n",
    "        \"\"\"\n",
    "        conn = sqlite3.connect(database_name)\n",
    "        cursor = conn.cursor()\n",
    "        table_name=cursor.execute(\"SELECT name FROM sqlite_master\").fetchall()[0][0]\n",
    "        columns_info = cursor.execute(f\"PRAGMA table_info({table_name});\").fetchall()\n",
    "        table_description=f\"Table name :[table]\\n(column_index, column_name, data_type, not_null, default_value, primary_key)\\n{columns_info}\"\n",
    "        return table_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table name: [table]\n",
      "Column:\n",
      "column name: [col0] - data type: primary key\n",
      "column name :[col1] - data type: NUMERIC  → Min: 4.3, Max: 7.9, Mean: 5.843333333333334\n",
      "column name :[col2] - data type: NUMERIC  → Min: 2, Max: 4.4, Mean: 3.0540000000000003\n",
      "column name :[col3] - data type: NUMERIC  → Min: 1, Max: 6.9, Mean: 3.758666666666666\n",
      "column name :[col4] - data type: NUMERIC  → Min: 0.1, Max: 2.5, Mean: 1.1986666666666668\n",
      "column name :[col5] - data type: TEXT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('database.sqlite')\n",
    "cursor = conn.cursor()\n",
    "table_name=cursor.execute(\"SELECT name FROM sqlite_master\").fetchall()[0][0]\n",
    "\n",
    "columns_info = cursor.execute(f\"PRAGMA table_info({table_name});\").fetchall()\n",
    "table_description=f\"Table name: [table]\\nColumn:\\n\"\n",
    "\n",
    "for n,columns_info in enumerate(columns_info):\n",
    "    col_type=columns_info[2].upper()\n",
    "    col_name=columns_info[1]\n",
    "    if columns_info[-1]:\n",
    "        col=f\"column name: [col{n}] - data type: primary key\\n\"\n",
    "        \n",
    "    else : \n",
    "        col=f\"column name :[col{n}] - data type: {col_type}\"\n",
    "        if col_type in (\"NUMERIC\",\"INTEGER\", \"REAL\"):\n",
    "            cursor.execute(f\"SELECT MIN({col_name}), MAX({col_name}), AVG({col_name}) FROM {table_name}\")\n",
    "            min_val, max_val, avg_val = cursor.fetchone()\n",
    "            col += f\"  → Min: {min_val}, Max: {max_val}, Mean: {avg_val}\"\n",
    "        \n",
    "        col+=\"\\n\"\n",
    "\n",
    "    table_description+=col\n",
    "    \n",
    "print(table_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Id', 'INTEGER', 0, None, 1),\n",
       " (1, 'SepalLengthCm', 'NUMERIC', 0, None, 0),\n",
       " (2, 'SepalWidthCm', 'NUMERIC', 0, None, 0),\n",
       " (3, 'PetalLengthCm', 'NUMERIC', 0, None, 0),\n",
       " (4, 'PetalWidthCm', 'NUMERIC', 0, None, 0),\n",
       " (5, 'Species', 'TEXT', 0, None, 0)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_info = cursor.execute(f\"PRAGMA table_info({table_name});\").fetchall()\n",
    "columns_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SELECT COUNT(*) AS [count], SUM([col1]) AS [total_col1], AVG([col2]) AS [avg_col2], MAX([col3]) AS [max_col3], MIN([col4]) AS [min_col4], [col0] FROM [table] GROUP BY [col5];\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "SYSTEM_PROMPT = f\"\"\" \n",
    "You are a helpful assistant that generates a only SQL placeholders. My ultimate goal is to discover as many diverse SQL as possible\n",
    "The user will provide: **Existing Queries**:  SELECT... Table(s) **Table Description**:\n",
    "\n",
    "Your Task\n",
    "- Generate \"one\" SQL query that is distinct from the user's queries and make it very diffrent than user's queries.\n",
    "- Ensure the query is meaningful and practical for real-world use cases.\n",
    "- Output only the SQL code**—no explanations, comments, or additional text or \"```sql\".\n",
    "- Maintain general placeholders:\n",
    "  - `[table]` for table names\n",
    "  - `[col]` for column names\n",
    "\n",
    "\n",
    "Output Query:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def get_table_info(database_name:str='database.sqlite')-> str:\n",
    "  \"\"\"\n",
    "  return description of dataset\n",
    "  \"\"\"\n",
    "  conn = sqlite3.connect('database.sqlite')\n",
    "  cursor = conn.cursor()\n",
    "  table_name=cursor.execute(\"SELECT name FROM sqlite_master\").fetchall()[0][0]\n",
    "\n",
    "  columns_info = cursor.execute(f\"PRAGMA table_info({table_name});\").fetchall()\n",
    "  table_description=f\"Table name: [table]\\nColumn:\\n\"\n",
    "\n",
    "  for n,columns_info in enumerate(columns_info):\n",
    "      col_type=columns_info[2].upper()\n",
    "      col_name=columns_info[1]\n",
    "      if columns_info[-1]:\n",
    "          col=f\"column name: [col{n}] - data type: primary key\\n\"\n",
    "          \n",
    "      else : \n",
    "          col=f\"column name :[col{n}] - data type: {col_type}\"\n",
    "          if col_type in (\"NUMERIC\",\"INTEGER\", \"REAL\"):\n",
    "              cursor.execute(f\"SELECT MIN({col_name}), MAX({col_name}), AVG({col_name}) FROM {table_name}\")\n",
    "              min_val, max_val, avg_val = cursor.fetchone()\n",
    "              col += f\"  → Min: {min_val}, Max: {max_val}, Mean: {avg_val}\"\n",
    "        \n",
    "          col+=\"\\n\"\n",
    "      table_description+=col   \n",
    "  return table_description\n",
    "table_description=get_table_info()\n",
    "sqls=[\"SELECT [col] * \\nFROM [table];\" ]\n",
    "from ollama import Client\n",
    "client = Client(\n",
    "  host='http://localhost:11434',\n",
    "  headers={'x-some-header': 'some-value'}\n",
    ")\n",
    "response = client.chat(model='deepseek-r1:14b', messages=[\n",
    "   {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "   {\"role\": \"user\", \"content\": f\"**Existing Queries**: {sqls } \\n**Table Description**: {table_description}\"},\n",
    "],)\n",
    "print(response.message[\"content\"].split(\"</think>\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ollama import Client\n",
    "client = Client(\n",
    "  host='http://localhost:11434',\n",
    "  headers={'x-some-header': 'some-value'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ChatResponse' object has no attribute 'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/pydantic/main.py:891\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 891\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChatResponse' object has no attribute 'choices'"
     ]
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "\n",
    "stream = chat(\n",
    "    model='llama3.2',\n",
    "    messages=[{'role': 'user', 'content': 'Why is the sky blue?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "def model_transformer(name: str,device=\"mps\"):\n",
    "    # Check if model is already saved on disk\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available(\n",
    "                                ) else \"cpu\") if device is None else device\n",
    "    model_name=\"models/\"+name\n",
    "    if os.path.exists(model_name):\n",
    "        print('yep')\n",
    "        model = SentenceTransformer(model_name, device=device,#token=HF_TOKEN,\n",
    "                                       trust_remote_code=True)\n",
    "    else:\n",
    "        model_name=name\n",
    "        # Save the model to disk\n",
    "        model = SentenceTransformer(model_name, device=device,#token=HF_TOKEN,\n",
    "                                       trust_remote_code=True)\n",
    "        model.save(\"models/\"+name)\n",
    "    return model\n",
    "transModel = model_transformer(\"Alibaba-NLP/gte-large-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name= \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "#from requests.exceptions import HTTPError\n",
    "#client = InferenceClient(api_key=HF_TOKEN)\n",
    "def call_llm(messages: str=None, \n",
    "             ) -> str:\n",
    "    if False:\n",
    "        output = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        max_tokens=265, \n",
    "        temperature=0.5,\n",
    "        top_p=0.9,\n",
    "        stream=False,\n",
    "        seed=random.randint(0, 10000000)\n",
    "        ).choices[0].message.content\n",
    "\n",
    "    output = client.chat(model='deepseek-r1:32b', messages=messages).message[\"content\"].split(\"</think>\")[-1]\n",
    "\n",
    "#call_ret\n",
    "    return str(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SYSTEM_PROMPT = f\"\"\"\n",
    "You are a helpful assistant that generates a only SQL code. My ultimate goal is to discover as many diverse SQL as possible\n",
    "The user will provide: Provided Queries:  SELECT... Table(s) Description:\n",
    "\n",
    "Your Task\n",
    "- Generate \"one\" SQL query that is distinct from the user's queries and make it very diffrent than user's queries.\n",
    "- Ensure the query is meaningful and practical for real-world use cases.\n",
    "- Output only the SQL code**—no explanations, comments, or additional text or \"```sql\".\n",
    "\n",
    "never ever start with \"```sql\"\n",
    "\n",
    "Output Query:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"\n",
    "You are an AI SQL query generator placeholders. Your goal is to generate **one diverse and meaningful SQL query**.\n",
    "\n",
    "\n",
    "### Input:\n",
    "- **Existing Queries**: SELECT...\n",
    "- **Table Structure**: General description.\n",
    "\n",
    "### Your Task:\n",
    "- Generate **one distinct SQL query** that is **structurally different** from the provided queries but still practical.\n",
    "- Use **varied SQL techniques** (e.g., JOINs, aggregation, subqueries, window functions).\n",
    "- Ensure the query is **syntactically correct** and **real-world applicable**.\n",
    "\n",
    "\n",
    "### Output:\n",
    "- **Return only the SQL query** (no explanations, comments, or extra text).\n",
    "- **Example Output:**  \n",
    "  ```sql\n",
    "  SELECT [col], COUNT(DISTINCT [value]) FROM [table] GROUP BY [col];\n",
    "- Maintain **general placeholders**:\n",
    "  - `[table]` for table names\n",
    "  - `[col]` for column names\n",
    "  - `[value]` for values\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Optional\n",
    "import time\n",
    "import faiss\n",
    "\n",
    "\n",
    "class SkillLibrary:\n",
    "    def __init__(self, library_path=\"skills.json\"):\n",
    "        self.library_path = library_path\n",
    "        # Load from disk or init empty\n",
    "        if os.path.exists(library_path):\n",
    "            with open(library_path, \"rb\", encoding=\"utf-8\") as f:\n",
    "                self.skills = json.load(f)\n",
    "        else:\n",
    "            self.skills = {}\n",
    "\n",
    "        dim = 1024  #  the vector dimension \n",
    "        if len(self.skills)==0:\n",
    "            self.vect_index = faiss.IndexFlatIP(dim)# ini\n",
    "\n",
    "        else :self.vect_index = faiss.IndexFlatIP(dim)# to be done \n",
    "\n",
    "        self.selected_index=[] # list of random selected index of sql skills \n",
    "        self.selected_ret_index = [] # list of retrieved selected index of sql skills ]\n",
    "    def __repr__(self):\n",
    "        return self.skills\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.skills)\n",
    "\n",
    "\n",
    "    def save(self):\n",
    "        with open(self.library_path, \"wb\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.skills, f, indent=2)\n",
    "    \n",
    "    def get_sql(self,random_=True,num_q=5):\n",
    "        n_skill=len(self.skills)\n",
    "        if n_skill==0:\n",
    "            return [\"SELECT * \\nFROM [table];\" ]\n",
    "        if random_: \n",
    "            self.selected_index = random.sample(list(self.skills.keys()),k=min(num_q,n_skill\n",
    "                                                                )\n",
    "                                                ) \n",
    "            selected_sql = [self.skills[i][\"sql\"] for  i in  self.selected_index]\n",
    "        else:\n",
    "            n_skill-=1\n",
    "            selected_sql = [ self.skills[i] for i in range(n_skill,n_skill-num_q,-1) ]\n",
    "            self.selected_index = list(range(n_skill,n_skill-num_q,-1) )\n",
    "        \n",
    "        return selected_sql\n",
    "\n",
    "    def add_skill(self, sql: str, embedding_vec: List[float],python_func:str=None,save:bool=False)-> None:\n",
    "        \"\"\"\n",
    "        Add a new skill to the library with minimal info (only SQL).\n",
    "        \"\"\"\n",
    "        self.skills[len(self.skills)] = {\n",
    "            \"sql\" : sql,\n",
    "            \"embedding\": embedding_vec,\n",
    "            \"python_func\": python_func\n",
    "        }\n",
    "        self.vect_index.add(embedding_vec)\n",
    "        if save or len(self.skills)%100==0:\n",
    "            self.save()\n",
    "    \n",
    "    def find_similar(self, embedding_vec: List[float], top_k: int = 10, throushold:int=.9,) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return up to top_k skill names sorted by similarity (desc).\n",
    "        \"\"\"\n",
    "        # If skill library is empty, return empty\n",
    "        if not self.skills:\n",
    "            return []\n",
    "        \n",
    "        self.selected_ret_index=[]\n",
    "        # Compute similarity\n",
    "        sims, ret_index = self.vect_index.search(embedding_vec, k=top_k)\n",
    "        sims = sims[0]# because only one query\n",
    "        self.selected_ret_index=ret_index[0]# because only one query\n",
    "        self.selected_ret_index = [ self.selected_ret_index[i] for i in range(len(sims)\n",
    "                                                  )  if (sims[i] > throushold )]\n",
    "        ret_sql = [ self.skills[i]['sql'] for i in self.selected_ret_index  ] if len(self.selected_ret_index)>0 else []\n",
    "        \n",
    "        return ret_sql\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    def get_table_info(self,database_name:str='database.sqlite')-> str:\n",
    "        \"\"\"\n",
    "        return description of dataset\n",
    "        \"\"\"\n",
    "        conn = sqlite3.connect(database_name)\n",
    "        cursor = conn.cursor()\n",
    "        table_name=cursor.execute(\"SELECT name FROM sqlite_master\").fetchall()[0][0]\n",
    "        columns_info = cursor.execute(f\"PRAGMA table_info({table_name});\").fetchall()\n",
    "        table_description=f\"Table name :{table_name}\\n(column_index, column_name, data_type, not_null, default_value, primary_key)\\n{columns_info}\"\n",
    "        return table_description\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def test_sql_executable(sql_text: str, test_db_path=\":memory:\") -> bool:\n",
    "    \"\"\"\n",
    "    Quick check: parse & run the SQL in a small SQLite DB. If it fails, return False.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(test_db_path)\n",
    "        cursor = conn.cursor()\n",
    "        # We run the SQL. If the SQL is malformed or has some error, it fails.\n",
    "        cursor.execute(sql_text)  # or .executescript for multi-statement\n",
    "        # Optionally fetch or commit\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "\n",
    "class SQLCurriculumAgent():\n",
    "    \"\"\"\n",
    "    Inspired by 'Voyager' curriculum.\n",
    "    - For each 'round', propose N new SQL queries (diverse and complex).\n",
    "    - Validate each query. If invalid, we revise. If too similar, we revise.\n",
    "    - Then store it in skill library.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        #messages: list,\n",
    "        skill_library: SkillLibrary,\n",
    "        max_retries: int = 5,\n",
    "        transModel=None\n",
    "    ):\n",
    "        self.skill_library = skill_library\n",
    "        #self.sim_threshold = similarity_threshold\n",
    "        self.max_retries = max_retries\n",
    "        self.messages=None\n",
    "        self.path_table=None\n",
    "    \n",
    "        self.model = transModel #model_transformer(\"Alibaba-NLP/gte-large-en-v1.5\")\n",
    "\n",
    "\n",
    "    def prompt_messages(self, SYSTEM_PROMPT,table_description):\n",
    "        sqls= self.skill_library.get_sql(random_=True)\n",
    "        self.messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": f\"**Existing Queries**: {sqls } \\n**Table Description**: {table_description}\"},\n",
    "            ]\n",
    "\n",
    "    def create_info_table(self,path_table):\n",
    "        if path_table == self.path_table: return\n",
    "        self.path_table=path_table\n",
    "        self.table_info= self.skill_library.get_table_info(path_table)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.skill_library.skills)\n",
    "    \n",
    "    \n",
    "    def propose_sql_queries(self,path_table,SYSTEM_PROMPT) -> List[str]:\n",
    "        \"\"\"\n",
    "        Use your LLM to propose a diverse SQL query.\n",
    "        \"\"\"\n",
    "        self.create_info_table(path_table)#if get new table info\n",
    "\n",
    "        if not self.messages :\n",
    "            self.prompt_messages(SYSTEM_PROMPT,self.table_info)\n",
    "        # retrun one or more queires \n",
    "        try:\n",
    "            query =  call_llm(self.messages)\n",
    "        except HTTPError as e:\n",
    "            print(\"HTTPError\")\n",
    "            time.sleep(3)\n",
    "            query =  call_llm(self.messages)\n",
    "        #some preProsses\n",
    "        query_embed = self.compute_embedding(query)\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": query})\n",
    "        retrieve_skill=self.skill_library.find_similar( query_embed,self.max_retries )\n",
    "        if len(retrieve_skill)>0:\n",
    "            print(\"\\n\")\n",
    "            print(\"***********************************************************\")\n",
    "            print(f\"Retrrived and query: {query}\")\n",
    "            print(f\"is similar to existing queries: {retrieve_skill}\")\n",
    "            print(\"***********************************************************\")\n",
    "            print(\"\\n\")\n",
    "            self.messages.append({f\"role\": \"user\", \"content\": \"Not good because the previously generated query is very similar to the following SQL queries: {retrieve_skill}\"})\n",
    "            query,query_embed = self.propose_sql_queries(path_table,SYSTEM_PROMPT)\n",
    "        if len(self)>0:\n",
    "            prev=self.skill_library.skills[len(self)-1]\n",
    "            sec_cond= (np.dot(query_embed, prev[\"embedding\"].T)/(np.linalg.norm(query_embed)*np.linalg.norm(prev[\"embedding\"])))[0][0]\n",
    "            print(sec_cond)\n",
    "            if sec_cond < .6:\n",
    "                print(\"\\n\")\n",
    "                print(\"***********************************************************\")\n",
    "                print(f\"Seconde err and query: {query}\")\n",
    "                print(f\"is not similar at all to to existing queries: {prev['sql']}\")\n",
    "                print(\"***********************************************************\")\n",
    "                print(\"\\n\")\n",
    "                self.messages.append({\"role\": \"user\", \"content\": f\"Not good because the previously generated query is incorrect or too different from the previous SQL query: {prev['sql']}. it should be a bit different. Rewrite it.\"})\n",
    "                query,query_embed = self.propose_sql_queries(path_table,SYSTEM_PROMPT)\n",
    " \n",
    "\n",
    "        \n",
    "\n",
    "        return query,query_embed\n",
    "    \n",
    "    def compute_embedding(self,text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Compute embedding (e.g. using sentence-transformers or OpenAI embeddings).\n",
    "        Return a vector as a list of floats.\n",
    "        \"\"\"\n",
    "        # Example pseudocode:\n",
    "        # from sentence_transformers import SentenceTransformer\n",
    "        embedding = self.model.encode([text], convert_to_tensor=False\n",
    "                        ,batch_size=32,show_progress_bar=False,normalize_embeddings=True)\n",
    "        \n",
    "\n",
    "        return np.array(embedding, dtype=np.float32)\n",
    "lib=SkillLibrary(\"\")\n",
    "Curricu=SQLCurriculumAgent(lib,max_retries=5,transModel=transModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query_embe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mquery_embe\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'query_embe' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query °1: \n",
      "\n",
      "\n",
      "WITH IrisCalculations AS (\n",
      "    SELECT \n",
      "        Id,\n",
      "        Species,\n",
      "        SepalLengthCm * SepalWidthCm AS SepalArea,\n",
      "        PetalLengthCm * PetalWidthCm AS PetalArea\n",
      "    FROM Iris\n",
      ")\n",
      "SELECT \n",
      "    Species,\n",
      "    COUNT(*) AS TotalCount,\n",
      "    AVG(SepalArea) AS AvgSepalArea,\n",
      "    MIN(PetalArea) AS MinPetalArea,\n",
      "    MAX(PetalArea) AS MaxPetalArea\n",
      "FROM IrisCalculations\n",
      "WHERE Species = 'setosa'\n",
      "GROUP BY Species\n",
      "ORDER BY MaxPetalArea DESC; \n",
      "is added.\n",
      "---------------------------------------------------------------\n",
      "0.8754664\n",
      "Query °2: \n",
      "\n",
      "\n",
      "SELECT \n",
      "    Species,\n",
      "    CASE \n",
      "        WHEN SepalWidthCm < 3 THEN 'Small'\n",
      "        WHEN SepalWidthCm BETWEEN 3 AND 4 THEN 'Medium'\n",
      "        ELSE 'Large' \n",
      "    END AS WidthCategory,\n",
      "    COUNT(*) AS Count,\n",
      "    AVG(PetalLengthCm) AS AvgPetalLength,\n",
      "    MAX(SepalLengthCm) AS MaxSepalLength\n",
      "FROM Iris\n",
      "GROUP BY Species, WidthCategory\n",
      "ORDER BY Species ASC, WidthCategory DESC; \n",
      "is added.\n",
      "---------------------------------------------------------------\n",
      "0.81803966\n",
      "Query °3: \n",
      "\n",
      "\n",
      "SELECT Id, Species, SepalLengthCm, PetalLengthCm, (PetalLengthCm - SepalLengthCm) AS LengthDifference FROM Iris WHERE PetalLengthCm > 2 * SepalLengthCm ORDER BY LengthDifference DESC; \n",
      "is added.\n",
      "---------------------------------------------------------------\n",
      "0.7407548\n",
      "Query °4: \n",
      "\n",
      "\n",
      "SELECT \n",
      "    Species,\n",
      "    COUNT(CASE WHEN SepalLengthCm IS NULL THEN 1 END) AS SepalLengthNullCount,\n",
      "    COUNT(CASE WHEN SepalWidthCm IS NULL THEN 1 END) AS SepalWidthNullCount,\n",
      "    COUNT(CASE WHEN PetalLengthCm IS NULL THEN 1 END) AS PetalLengthNullCount,\n",
      "    COUNT(CASE WHEN PetalWidthCm IS NULL THEN 1 END) AS PetalWidthNullCount\n",
      "FROM Iris\n",
      "GROUP BY Species; \n",
      "is added.\n",
      "---------------------------------------------------------------\n",
      "0.74816245\n",
      "Query °5: \n",
      "\n",
      "\n",
      "SELECT Species, \n",
      "       AVG(PetalLengthCm / SepalLengthCm) AS PetalToSepalLengthRatio,\n",
      "       AVG(PetalWidthCm / SepalWidthCm) AS PetalToSepalWidthRatio\n",
      "FROM Iris\n",
      "GROUP BY Species\n",
      "ORDER BY PetalToSepalLengthRatio ASC; \n",
      "is added.\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "***********************************************************\n",
      "Retrrived and query: \n",
      "\n",
      "SELECT Species,\n",
      "       CASE \n",
      "           WHEN SepalLengthCm > 5 AND PetalLengthCm > 2 THEN 'Large'\n",
      "           WHEN SepalLengthCm BETWEEN 4 AND 5 AND PetalLengthCm BETWEEN 1.5 AND 2 THEN 'Medium'\n",
      "           ELSE 'Small' \n",
      "       END AS SizeCategory,\n",
      "       COUNT(*) AS Count\n",
      "FROM Iris\n",
      "GROUP BY Species, SizeCategory\n",
      "ORDER BY Species, SizeCategory;\n",
      "is similar to existing queries: [\"\\n\\nSELECT \\n    Species,\\n    CASE \\n        WHEN SepalWidthCm < 3 THEN 'Small'\\n        WHEN SepalWidthCm BETWEEN 3 AND 4 THEN 'Medium'\\n        ELSE 'Large' \\n    END AS WidthCategory,\\n    COUNT(*) AS Count,\\n    AVG(PetalLengthCm) AS AvgPetalLength,\\n    MAX(SepalLengthCm) AS MaxSepalLength\\nFROM Iris\\nGROUP BY Species, WidthCategory\\nORDER BY Species ASC, WidthCategory DESC;\"]\n",
      "***********************************************************\n",
      "\n",
      "\n",
      "0.77080214\n",
      "0.77080214\n",
      "Query °6: \n",
      "\n",
      "\n",
      "```sql\n",
      "WITH OrderedIris AS (\n",
      "    SELECT \n",
      "        Species,\n",
      "        SepalWidthCm,\n",
      "        PetalLengthCm,\n",
      "        SUM(PetalLengthCm) OVER (PARTITION BY Species ORDER BY SepalWidthCm) AS CumulativePetalSum\n",
      "    FROM Iris\n",
      ")\n",
      "SELECT * FROM OrderedIris;\n",
      "``` \n",
      "is added.\n",
      "---------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'HTTPError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 178\u001b[0m, in \u001b[0;36mSQLCurriculumAgent.propose_sql_queries\u001b[0;34m(self, path_table, SYSTEM_PROMPT)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     query \u001b[38;5;241m=\u001b[39m  \u001b[43mcall_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mcall_llm\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m      7\u001b[0m         output \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      8\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m      9\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m265\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m         seed\u001b[38;5;241m=\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10000000\u001b[39m)\n\u001b[1;32m     14\u001b[0m         )\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m---> 16\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeepseek-r1:32b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</think>\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#call_ret\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/ollama/_client.py:333\u001b[0m, in \u001b[0;36mClient.chat\u001b[0;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03mCreate a chat response using the requested model.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03mReturns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m  \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m  \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/ollama/_client.py:178\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/ollama/_client.py:118\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m   r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m   r\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpx/_client.py:825\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    813\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    814\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    824\u001b[0m )\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deepsqlex/lib/python3.9/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     sql_query,query_embed \u001b[38;5;241m=\u001b[39m \u001b[43mCurricu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropose_sql_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatabase.sqlite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mSYSTEM_PROMPT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery °\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msql_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mis added.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     lib\u001b[38;5;241m.\u001b[39madd_skill(sql_query, query_embed)\n",
      "Cell \u001b[0;32mIn[15], line 179\u001b[0m, in \u001b[0;36mSQLCurriculumAgent.propose_sql_queries\u001b[0;34m(self, path_table, SYSTEM_PROMPT)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     query \u001b[38;5;241m=\u001b[39m  call_llm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages)\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mHTTPError\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTPError\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    181\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HTTPError' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    sql_query,query_embed = Curricu.propose_sql_queries('database.sqlite',SYSTEM_PROMPT)\n",
    "    print(f\"Query °{i+1}: \\n{sql_query} \\nis added.\")\n",
    "    lib.add_skill(sql_query, query_embed)\n",
    "    Curricu.messages=None\n",
    "    print(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint,token=\"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\",device='mps')\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint,token=\"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\",device='mps')  # You may want to use bfloat16 and/or move to GPU here\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
    " ]\n",
    "tokenized_chat = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\"\n",
    "                                               )\n",
    "\n",
    "print(tokenizer.decode(tokenized_chat[0]))\n",
    "outputs = model.generate(tokenized_chat, max_new_tokens=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsqlex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
